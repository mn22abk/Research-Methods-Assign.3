{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mn22abk/Research-Methods-Assign.3/blob/main/Fine_Tuned_MLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "416177b8",
      "metadata": {
        "id": "416177b8"
      },
      "source": [
        "### Cell 1: Installing Transformers Library\n",
        "\n",
        "This cell installs the `transformers` library using pip. The Transformers library is necessary for working with pre-trained models provided by Hugging Face for various natural language processing tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cd8c5d8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd8c5d8a",
        "outputId": "b082b238-b93c-41dd-a925-5a0c4ffb0172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b9a2053",
      "metadata": {
        "id": "5b9a2053"
      },
      "source": [
        "### Cell 2: Using Sentiment Analysis Pipeline\n",
        "\n",
        "This cell demonstrates the use of the sentiment analysis pipeline provided by the `transformers` library. It loads a pre-trained sentiment analysis model using the `pipeline` function and analyzes the sentiment of a single input text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3f9501c4",
      "metadata": {
        "id": "3f9501c4"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a764191d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a764191d",
        "outputId": "6b179da7-9e74-4c08-dc2f-32bc84a09455"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998658895492554}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "classifier('We are very happy for the holiday of Eid.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b8592b18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8592b18",
        "outputId": "5a99c4bb-91e0-422d-b57f-10977e0343f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9997395873069763}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "classifier('My first job was not good because of tight schedule.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21ada437",
      "metadata": {
        "id": "21ada437"
      },
      "source": [
        "### Cell 5: Performing Sentiment Analysis on Multiple Texts\n",
        "\n",
        "This cell extends the sentiment analysis task to handle multiple input texts at once. It uses the same sentiment analysis pipeline to analyze the sentiment of multiple input texts and prints the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "41376b84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41376b84",
        "outputId": "54394af3-4081-4d26-eaf6-9ed3d306a72a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: POSITIVE, with score: 0.9998\n",
            "label: NEGATIVE, with score: 0.5309\n"
          ]
        }
      ],
      "source": [
        "results = classifier([\"We are very happy to show you the ðŸ¤— Transformers library.\",\n",
        "           \"We hope you don't hate it.\"])\n",
        "for result in results:\n",
        "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8a1d0isSYa_V"
      },
      "id": "8a1d0isSYa_V",
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}